{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credential Scheme Benchmark Analysis\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "# Configuration settings\n",
    "BASE_DIR = Path(\"../target/criterion\")\n",
    "OUTPUT_DIR = Path(\"./benchmark_analysis\")\n",
    "\n",
    "# Scheme configuration\n",
    "SCHEME_DIRS = {\n",
    "    \"bbs_plus_og_anoncreds\": \"bbs_plus_og\",\n",
    "    \"ps_anoncreds\": \"ps\",\n",
    "    \"bbs_plus_16_anoncreds\": \"bbs_plus_16\",\n",
    "    \"ps_utt_anoncreds_std\": \"ps_utt_std\",\n",
    "    \"ps_utt_anoncreds_imp\": \"ps_utt_imp\"\n",
    "}\n",
    "\n",
    "# Display names for schemes (in desired order)\n",
    "SCHEME_NAMES = {\n",
    "    \"bbs_plus_og\": \"BBS+ 06\",\n",
    "    \"ps\": \"PS 16\",\n",
    "    \"bbs_plus_16\": \"BBS+ 16\",\n",
    "    \"ps_utt_std\": \"PS-UTT G1\",\n",
    "    \"ps_utt_imp\": \"PS-UTT G2\"\n",
    "}\n",
    "\n",
    "# Ordered list of schemes for consistent visualization\n",
    "SCHEME_ORDER = [\n",
    "    \"bbs_plus_og\",\n",
    "    \"bbs_plus_16\",\n",
    "    \"ps\",\n",
    "    \"ps_utt_std\",\n",
    "    \"ps_utt_imp\"\n",
    "]\n",
    "\n",
    "# Focus only on the requested operations\n",
    "OPERATIONS = [\"obtain\", \"issue\", \"show\", \"verify\"]\n",
    "\n",
    "# Custom color palette grouping schemes by family\n",
    "SCHEME_COLORS = {\n",
    "    \"bbs_plus_og\": \"#4169E1\",  # Royal Blue for BBS+ OG\n",
    "    \"bbs_plus_16\": \"#87CEFA\",  # Light Sky Blue for BBS+ 16\n",
    "    \"ps\": \"#FF8C00\",          # Dark Orange for PS Standard\n",
    "    \"ps_utt_std\": \"#CD5C5C\",  # Indian Red for PS-UTT Standard\n",
    "    \"ps_utt_imp\": \"#E9967A\",  # Dark Salmon for PS-UTT Improved\n",
    "}\n",
    "\n",
    "# Use our custom scheme colors instead of the default palette\n",
    "COLORS = [SCHEME_COLORS[scheme] for scheme in SCHEME_ORDER]\n",
    "\n",
    "# Visualization settings\n",
    "MESSAGE_SIZES_TO_VISUALIZE = [5, 10, 20, 30]\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_benchmark_data(base_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Extract benchmark data from Criterion output directories.\"\"\"\n",
    "    print(f\"Extracting benchmark data from {base_dir}\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # Process each scheme directory\n",
    "    for scheme_dir in base_dir.iterdir():\n",
    "        if not scheme_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        scheme_key = scheme_dir.name\n",
    "        if scheme_key not in SCHEME_DIRS:\n",
    "            print(f\"Skipping unknown directory: {scheme_key}\")\n",
    "            continue\n",
    "\n",
    "        # Map directory name to scheme identifier\n",
    "        scheme = SCHEME_DIRS[scheme_key]\n",
    "        print(f\"Processing scheme: {SCHEME_NAMES.get(scheme, scheme)}\")\n",
    "\n",
    "        # Process each benchmark directory\n",
    "        for bench_dir in scheme_dir.iterdir():\n",
    "            if not bench_dir.is_dir() or bench_dir.name == \"report\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Parse benchmark directory name\n",
    "                bench_name = bench_dir.name\n",
    "\n",
    "                # Try both formats: operation_messages_N and scheme_operation_messages_N\n",
    "                match = re.search(r'(?:[a-z_]+_)?([a-z]+)_messages_(\\d+)', bench_name)\n",
    "                if not match:\n",
    "                    print(f\"  Skipping {bench_name}: Unable to parse benchmark name format\")\n",
    "                    continue\n",
    "\n",
    "                operation = match.group(1)  # operation name\n",
    "                msg_size = int(match.group(2))\n",
    "\n",
    "                # Only include operations we're interested in\n",
    "                if operation not in OPERATIONS:\n",
    "                    continue\n",
    "\n",
    "                # Find and load the estimates.json file\n",
    "                estimates_file = bench_dir / \"new\" / \"estimates.json\"\n",
    "                if not estimates_file.exists():\n",
    "                    print(f\"  Skipping {bench_name}: No estimates file found\")\n",
    "                    continue\n",
    "\n",
    "                with open(estimates_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract key metrics (converting from ns to ms)\n",
    "                mean_time = data[\"mean\"][\"point_estimate\"] / 1_000_000\n",
    "                std_dev = data[\"mean\"][\"standard_error\"] / 1_000_000\n",
    "                median = data[\"median\"][\"point_estimate\"] / 1_000_000\n",
    "                min_time = data[\"slope\"][\"point_estimate\"] / 1_000_000  # Best case\n",
    "\n",
    "                all_data.append({\n",
    "                    \"scheme\": scheme,\n",
    "                    \"display_name\": SCHEME_NAMES.get(scheme, scheme),\n",
    "                    \"operation\": operation,\n",
    "                    \"msg_size\": msg_size,\n",
    "                    \"mean_ms\": mean_time,\n",
    "                    \"median_ms\": median,\n",
    "                    \"std_dev_ms\": std_dev,\n",
    "                    \"min_ms\": min_time\n",
    "                })\n",
    "\n",
    "                print(f\"  Processed: {scheme_dir.name}/{bench_name} - {mean_time:.2f} ms\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {bench_dir.name}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No valid benchmark data found!\")\n",
    "\n",
    "    # Convert to DataFrame and apply basic cleaning\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Add scheme_order column based on SCHEME_ORDER for consistent sorting\n",
    "    order_map = {scheme: i for i, scheme in enumerate(SCHEME_ORDER)}\n",
    "    df['scheme_order'] = df['scheme'].map(lambda x: order_map.get(x, 999))\n",
    "\n",
    "    # Ensure operations are in standard order for visualization\n",
    "    op_order = {op: i for i, op in enumerate(OPERATIONS)}\n",
    "    df['op_order'] = df['operation'].map(lambda x: op_order.get(x, 999))\n",
    "\n",
    "    # Sort by scheme order, msg_size, and operation order\n",
    "    df = df.sort_values(['scheme_order', 'msg_size', 'op_order'])\n",
    "\n",
    "    # Drop sorting columns\n",
    "    df = df.drop(columns=['scheme_order', 'op_order'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_to_csv(df, base_dir=\"z_py_tests\"):\n",
    "    \"\"\"Save the benchmark data to a CSV file with date-time in the filename.\"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    csv_dir = Path(base_dir)\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate filename with current date and time\n",
    "    now = datetime.datetime.now()\n",
    "    date_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"anoncred_analysis_{date_time_str}.csv\"\n",
    "    \n",
    "    # Full path to save the CSV\n",
    "    csv_path = csv_dir / filename\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"Saved benchmark data to {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "# Execute the extraction and CSV saving\n",
    "benchmark_df = extract_benchmark_data(BASE_DIR)\n",
    "csv_path = save_to_csv(benchmark_df)\n",
    "print(f\"Data extraction complete. CSV saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_comparison_charts(df: pd.DataFrame):\n",
    "    \"\"\"Create performance comparison graphs for specified message sizes with increased spacing.\"\"\"\n",
    "    # Get available schemes in the preferred order\n",
    "    available_schemes = [s for s in SCHEME_ORDER if s in df['scheme'].unique()]\n",
    "\n",
    "    # Create figures for each message size\n",
    "    figures = {}\n",
    "\n",
    "    for msg_size in MESSAGE_SIZES_TO_VISUALIZE:\n",
    "        msg_data = df[df['msg_size'] == msg_size]\n",
    "        if msg_data.empty:\n",
    "            print(f\"No data for {msg_size} messages, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Filter operations that exist in the data\n",
    "        available_ops = msg_data['operation'].unique()\n",
    "        ops_to_use = [op for op in OPERATIONS if op in available_ops]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        bar_width = 0.25  # Narrower width to accommodate more schemes\n",
    "        group_spacing = 0.4  # Add spacing between operation groups\n",
    "\n",
    "        # Create wider spacing between operation groups\n",
    "        index = np.arange(len(ops_to_use)) * (1 + group_spacing)\n",
    "\n",
    "        for i, scheme in enumerate(available_schemes):\n",
    "            scheme_data = msg_data[msg_data['scheme'] == scheme]\n",
    "            if not scheme_data.empty:\n",
    "                # Ensure data is ordered by operation\n",
    "                op_means = []\n",
    "                for op in ops_to_use:\n",
    "                    op_mean = scheme_data[scheme_data['operation'] == op]['mean_ms'].values\n",
    "                    op_means.append(op_mean[0] if len(op_mean) > 0 else 0)\n",
    "\n",
    "                # Use scheme-specific color instead of palette index\n",
    "                ax.bar(\n",
    "                    index + i * bar_width,\n",
    "                    op_means,\n",
    "                    bar_width,\n",
    "                    label=SCHEME_NAMES.get(scheme, scheme),\n",
    "                    color=SCHEME_COLORS[scheme]  # Use scheme-specific color\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Operation')\n",
    "        ax.set_ylabel('Time (ms)')\n",
    "        ax.set_title(f'Performance Comparison at {msg_size} Messages')\n",
    "        ax.set_xticks(index + (len(available_schemes) - 1) * bar_width / 2)\n",
    "        ax.set_xticklabels([op.capitalize() for op in ops_to_use])\n",
    "        ax.legend()\n",
    "\n",
    "        # Add gridlines for better readability\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        figures[msg_size] = fig\n",
    "\n",
    "        print(f\"Created performance comparison chart for {msg_size} messages\")\n",
    "\n",
    "    return figures\n",
    "\n",
    "def create_operation_performance_charts(df: pd.DataFrame):\n",
    "    \"\"\"Create line charts showing performance by message count for each operation.\"\"\"\n",
    "    # Get available schemes in the preferred order\n",
    "    available_schemes = [s for s in SCHEME_ORDER if s in df['scheme'].unique()]\n",
    "\n",
    "    # Create a figure for each operation\n",
    "    figures = {}\n",
    "\n",
    "    for operation in OPERATIONS:\n",
    "        # Filter data for this operation\n",
    "        op_data = df[df['operation'] == operation]\n",
    "        if op_data.empty:\n",
    "            print(f\"No data for operation {operation}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Create a figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        # Plot a line for each scheme\n",
    "        for i, scheme in enumerate(available_schemes):\n",
    "            scheme_data = op_data[op_data['scheme'] == scheme]\n",
    "            if not scheme_data.empty:\n",
    "                # Sort by message size\n",
    "                scheme_data = scheme_data.sort_values('msg_size')\n",
    "\n",
    "                # Plot the line using scheme-specific color\n",
    "                ax.plot(\n",
    "                    scheme_data['msg_size'],\n",
    "                    scheme_data['mean_ms'],\n",
    "                    'o-',\n",
    "                    label=SCHEME_NAMES.get(scheme, scheme),\n",
    "                    color=SCHEME_COLORS[scheme]  # Use scheme-specific color\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Number of Messages')\n",
    "        ax.set_ylabel('Time (ms)')\n",
    "        ax.set_title(f'{operation.capitalize()} Operation Performance')\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax.legend()\n",
    "\n",
    "        # Ensure x-axis shows only the message sizes we have\n",
    "        ax.set_xticks(sorted(df['msg_size'].unique()))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        figures[operation] = fig\n",
    "\n",
    "        print(f\"Created performance chart for {operation} operation\")\n",
    "\n",
    "    return figures\n",
    "\n",
    "# Execute chart creation (using the DataFrame from the previous cell)\n",
    "try:\n",
    "    comparison_charts = create_performance_comparison_charts(benchmark_df)\n",
    "    operation_charts = create_operation_performance_charts(benchmark_df)\n",
    "    print(\"Chart creation complete!\")\n",
    "except NameError:\n",
    "    print(\"Error: benchmark_df not found. Please run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_operation_tables(df):\n",
    "    \"\"\"Create a separate DataFrame table for each operation.\"\"\"\n",
    "    operation_tables = {}\n",
    "    \n",
    "    for operation in OPERATIONS:\n",
    "        # Filter data for this operation\n",
    "        op_data = df[df['operation'] == operation]\n",
    "        if op_data.empty:\n",
    "            print(f\"No data for operation {operation}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Create a pivot table: message sizes in rows, schemes in columns\n",
    "        pivot = op_data.pivot_table(\n",
    "            index='msg_size',\n",
    "            columns='display_name', \n",
    "            values='mean_ms',\n",
    "            aggfunc='first'  # Just take the first value since each combo should be unique\n",
    "        )\n",
    "        \n",
    "        # Sort the index (message sizes)\n",
    "        pivot = pivot.sort_index()\n",
    "        \n",
    "        # Reorder columns based on SCHEME_NAMES order\n",
    "        ordered_columns = [SCHEME_NAMES[scheme] for scheme in SCHEME_ORDER \n",
    "                          if SCHEME_NAMES[scheme] in pivot.columns]\n",
    "        pivot = pivot[ordered_columns]\n",
    "        \n",
    "        # Add to dictionary\n",
    "        operation_tables[operation] = pivot\n",
    "        \n",
    "        # Display table\n",
    "        print(f\"\\n{operation.capitalize()} Operation (time in ms):\")\n",
    "        display(pivot.style.format(\"{:.2f}\"))  # Format to 2 decimal places\n",
    "        \n",
    "    return operation_tables\n",
    "\n",
    "# Create and display tables after charts\n",
    "operation_tables = create_operation_tables(benchmark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_operation_tables(df):\n",
    "    \"\"\"Create tables with additional statistics comparing schemes.\"\"\"\n",
    "    operation_tables = {}\n",
    "    \n",
    "    for operation in OPERATIONS:\n",
    "        # Filter data for this operation\n",
    "        op_data = df[df['operation'] == operation]\n",
    "        if op_data.empty:\n",
    "            print(f\"No data for operation {operation}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Create a pivot table with raw values\n",
    "        pivot = op_data.pivot_table(\n",
    "            index='msg_size',\n",
    "            columns='display_name', \n",
    "            values='mean_ms',\n",
    "            aggfunc='first'\n",
    "        )\n",
    "        \n",
    "        # Sort the index\n",
    "        pivot = pivot.sort_index()\n",
    "        \n",
    "        # Reorder columns based on SCHEME_NAMES order\n",
    "        ordered_columns = [SCHEME_NAMES[scheme] for scheme in SCHEME_ORDER \n",
    "                          if SCHEME_NAMES[scheme] in pivot.columns]\n",
    "        pivot = pivot[ordered_columns]\n",
    "        \n",
    "        # Add to dictionary\n",
    "        operation_tables[operation] = pivot\n",
    "        \n",
    "        # Display raw timing table\n",
    "        print(f\"\\n{operation.capitalize()} Operation (time in ms):\")\n",
    "        display(pivot.style.format(\"{:.2f}\"))\n",
    "        \n",
    "        # Find fastest scheme for each message size\n",
    "        fastest = pivot.idxmin(axis=1)\n",
    "        \n",
    "        # Create percentage comparison table (relative to fastest)\n",
    "        percentage = pivot.copy()\n",
    "        for idx in pivot.index:\n",
    "            fastest_scheme = fastest[idx]\n",
    "            fastest_time = pivot.loc[idx, fastest_scheme]\n",
    "            for col in pivot.columns:\n",
    "                percentage.loc[idx, col] = (pivot.loc[idx, col] / fastest_time - 1) * 100\n",
    "                \n",
    "        # Display percentage table\n",
    "        print(f\"\\n{operation.capitalize()} Comparison (% slower than fastest):\")\n",
    "        display(percentage.style.format(\"{:.1f}%\"))\n",
    "        \n",
    "    return operation_tables\n",
    "operation_tables2 = create_enhanced_operation_tables(benchmark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_tables(df):\n",
    "    \"\"\"Generate LaTeX tables for each operation.\"\"\"\n",
    "    latex_tables = {}\n",
    "    \n",
    "    for operation in OPERATIONS:\n",
    "        # Filter data for this operation\n",
    "        op_data = df[df['operation'] == operation]\n",
    "        if op_data.empty:\n",
    "            print(f\"No data for operation {operation}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Create a pivot table\n",
    "        pivot = op_data.pivot_table(\n",
    "            index='msg_size',\n",
    "            columns='display_name', \n",
    "            values='mean_ms',\n",
    "            aggfunc='first'\n",
    "        )\n",
    "        \n",
    "        # Sort the index\n",
    "        pivot = pivot.sort_index()\n",
    "        \n",
    "        # Reorder columns based on SCHEME_NAMES order\n",
    "        ordered_columns = [SCHEME_NAMES[scheme] for scheme in SCHEME_ORDER \n",
    "                          if SCHEME_NAMES[scheme] in pivot.columns]\n",
    "        pivot = pivot[ordered_columns]\n",
    "        \n",
    "        # Generate LaTeX table with customizations\n",
    "        latex_code = pivot.to_latex(\n",
    "            float_format=\"%.2f\",  # Format to 2 decimal places\n",
    "            bold_rows=True,       # Bold the row labels (message sizes)\n",
    "            caption=f\"Performance of {operation.capitalize()} Operation (time in ms)\",\n",
    "            label=f\"tab:{operation}_performance\",\n",
    "            position=\"htbp\"       # Standard LaTeX table positioning\n",
    "        )\n",
    "        \n",
    "        # Apply additional LaTeX formatting\n",
    "        latex_code = latex_code.replace('\\\\begin{table}', '\\\\begin{table}[htbp]\\n\\\\centering')\n",
    "        \n",
    "        # Add midrule after header\n",
    "        header_end = latex_code.find('\\\\\\\\', latex_code.find('\\\\toprule'))\n",
    "        if header_end != -1:\n",
    "            latex_code = latex_code[:header_end+2] + '\\\\midrule\\n' + latex_code[header_end+2:]\n",
    "        \n",
    "        # Store the LaTeX code\n",
    "        latex_tables[operation] = latex_code\n",
    "        \n",
    "        # Print the LaTeX code\n",
    "        print(f\"\\nLaTeX Table for {operation.capitalize()} Operation:\")\n",
    "        print(latex_code)\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        \n",
    "    return latex_tables\n",
    "\n",
    "# Generate LaTeX tables\n",
    "latex_tables = generate_latex_tables(benchmark_df)\n",
    "\n",
    "# If you want to save to files\n",
    "for operation, latex_code in latex_tables.items():\n",
    "    with open(f\"latex_table_{operation}.tex\", \"w\") as f:\n",
    "        f.write(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_operation_tables3(df):\n",
    "    \"\"\"Create a separate DataFrame table for each operation and summary tables.\"\"\"\n",
    "    operation_tables = {}\n",
    "    \n",
    "    # First, create individual operation tables\n",
    "    for operation in OPERATIONS:\n",
    "        # Filter data for this operation\n",
    "        op_data = df[df['operation'] == operation]\n",
    "        if op_data.empty:\n",
    "            print(f\"No data for operation {operation}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Create a pivot table: message sizes in rows, schemes in columns\n",
    "        pivot = op_data.pivot_table(\n",
    "            index='msg_size',\n",
    "            columns='display_name', \n",
    "            values='mean_ms',\n",
    "            aggfunc='first'  # Just take the first value since each combo should be unique\n",
    "        )\n",
    "        \n",
    "        # Sort the index (message sizes)\n",
    "        pivot = pivot.sort_index()\n",
    "        \n",
    "        # Reorder columns based on SCHEME_NAMES order\n",
    "        ordered_columns = [SCHEME_NAMES[scheme] for scheme in SCHEME_ORDER \n",
    "                          if SCHEME_NAMES[scheme] in pivot.columns]\n",
    "        pivot = pivot[ordered_columns]\n",
    "        \n",
    "        # Add to dictionary\n",
    "        operation_tables[operation] = pivot\n",
    "        \n",
    "        # Display table\n",
    "        print(f\"\\n{operation.capitalize()} Operation (time in ms):\")\n",
    "        display(pivot.style.format(\"{:.2f}\"))\n",
    "    \n",
    "    # Create combined tables if we have the necessary operations\n",
    "    if 'obtain' in operation_tables and 'issue' in operation_tables:\n",
    "        # Create sum of obtain and issue\n",
    "        obtain_issue_sum = operation_tables['obtain'] + operation_tables['issue']\n",
    "        \n",
    "        # Display combined table\n",
    "        print(\"\\nIssuing Phase Total (Obtain + Issue) (time in ms):\")\n",
    "        display(obtain_issue_sum.style.format(\"{:.2f}\"))\n",
    "        \n",
    "        # Add to dictionary\n",
    "        operation_tables['obtain_issue_sum'] = obtain_issue_sum\n",
    "    \n",
    "    if 'show' in operation_tables and 'verify' in operation_tables:\n",
    "        # Create sum of show and verify\n",
    "        show_verify_sum = operation_tables['show'] + operation_tables['verify']\n",
    "        \n",
    "        # Display combined table\n",
    "        print(\"\\nShowing Phase Total (Show + Verify) (time in ms):\")\n",
    "        display(show_verify_sum.style.format(\"{:.2f}\"))\n",
    "        \n",
    "        # Add to dictionary\n",
    "        operation_tables['show_verify_sum'] = show_verify_sum\n",
    "    \n",
    "    # Generate a total table if all operations are present\n",
    "    if all(op in operation_tables for op in OPERATIONS):\n",
    "        total_sum = sum(operation_tables[op] for op in OPERATIONS)\n",
    "        \n",
    "        # Display total table\n",
    "        print(\"\\nTotal Time Across All Operations (time in ms):\")\n",
    "        display(total_sum.style.format(\"{:.2f}\"))\n",
    "        \n",
    "        # Add to dictionary\n",
    "        operation_tables['total_sum'] = total_sum\n",
    "        \n",
    "    return operation_tables\n",
    "operation_tables3 = create_operation_tables3(benchmark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_latex_table_with_summaries(df):\n",
    "    \"\"\"Generate a single LaTeX table with all operations combined, including summary rows.\"\"\"\n",
    "    \n",
    "    # Create a list to hold the rows for the final table\n",
    "    table_rows = []\n",
    "    \n",
    "    # Get available schemes in the preferred order\n",
    "    available_schemes = [s for s in SCHEME_ORDER if s in df['scheme'].unique()]\n",
    "    scheme_display_names = [SCHEME_NAMES[scheme] for scheme in available_schemes]\n",
    "    \n",
    "    # Create column headers string\n",
    "    column_headers = \"n & \" + \" & \".join(scheme_display_names)\n",
    "    \n",
    "    # Create operation tables dictionary to store the data for summaries\n",
    "    operation_pivot_tables = {}\n",
    "    \n",
    "    # Process each operation\n",
    "    for operation in OPERATIONS:\n",
    "        # Filter data for this operation\n",
    "        op_data = df[df['operation'] == operation]\n",
    "        if op_data.empty:\n",
    "            print(f\"No data for operation {operation}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Create a pivot table\n",
    "        pivot = op_data.pivot_table(\n",
    "            index='msg_size',\n",
    "            columns='display_name', \n",
    "            values='mean_ms',\n",
    "            aggfunc='first'\n",
    "        )\n",
    "        \n",
    "        # Store in dictionary for summary calculations\n",
    "        operation_pivot_tables[operation] = pivot\n",
    "        \n",
    "        # Sort the index\n",
    "        pivot = pivot.sort_index()\n",
    "        \n",
    "        # Reorder columns based on scheme_display_names\n",
    "        ordered_columns = [name for name in scheme_display_names if name in pivot.columns]\n",
    "        pivot = pivot[ordered_columns]\n",
    "        \n",
    "        # Find minimum value in each row to highlight\n",
    "        min_vals = pivot.min(axis=1)\n",
    "        \n",
    "        # Add operation header (centered)\n",
    "        table_rows.append(f\"\\\\multicolumn{{{len(ordered_columns)+1}}}{{c}}{{\\\\textbf{{{operation.capitalize()}}}}}  \\\\\\\\\")\n",
    "        table_rows.append(\"\\\\midrule\")\n",
    "        \n",
    "        # Add data rows for this operation\n",
    "        for idx in pivot.index:\n",
    "            row = [f\"\\\\textbf{{{idx}}}\"]\n",
    "            \n",
    "            for col in ordered_columns:\n",
    "                val = pivot.loc[idx, col]\n",
    "                # Bold if it's the minimum value\n",
    "                if val == min_vals[idx]:\n",
    "                    row.append(f\"\\\\textbf{{{val:.2f}}}\")\n",
    "                else:\n",
    "                    row.append(f\"{val:.2f}\")\n",
    "                    \n",
    "            table_rows.append(\" & \".join(row) + \" \\\\\\\\\")\n",
    "        \n",
    "        # Add spacing between operations\n",
    "        table_rows.append(\"\\\\midrule\")\n",
    "    \n",
    "    # Add summary tables if we have the required operations\n",
    "    if 'obtain' in operation_pivot_tables and 'issue' in operation_pivot_tables:\n",
    "        # Calculate sum\n",
    "        obtain_issue_sum = operation_pivot_tables['obtain'] + operation_pivot_tables['issue']\n",
    "        \n",
    "        # Reorder columns\n",
    "        ordered_columns = [name for name in scheme_display_names if name in obtain_issue_sum.columns]\n",
    "        obtain_issue_sum = obtain_issue_sum[ordered_columns]\n",
    "        \n",
    "        # Find minimum values\n",
    "        min_vals = obtain_issue_sum.min(axis=1)\n",
    "        \n",
    "        # Add summary header\n",
    "        table_rows.append(f\"\\\\multicolumn{{{len(ordered_columns)+1}}}{{c}}{{\\\\textbf{{Issuing Phase Total (Obtain + Issue)}}}}  \\\\\\\\\")\n",
    "        table_rows.append(\"\\\\midrule\")\n",
    "        \n",
    "        # Add data rows\n",
    "        for idx in obtain_issue_sum.index:\n",
    "            row = [f\"\\\\textbf{{{idx}}}\"]\n",
    "            \n",
    "            for col in ordered_columns:\n",
    "                val = obtain_issue_sum.loc[idx, col]\n",
    "                # Bold if it's the minimum value\n",
    "                if val == min_vals[idx]:\n",
    "                    row.append(f\"\\\\textbf{{{val:.2f}}}\")\n",
    "                else:\n",
    "                    row.append(f\"{val:.2f}\")\n",
    "                    \n",
    "            table_rows.append(\" & \".join(row) + \" \\\\\\\\\")\n",
    "        \n",
    "        table_rows.append(\"\\\\midrule\")\n",
    "    \n",
    "    if 'show' in operation_pivot_tables and 'verify' in operation_pivot_tables:\n",
    "        # Calculate sum\n",
    "        show_verify_sum = operation_pivot_tables['show'] + operation_pivot_tables['verify']\n",
    "        \n",
    "        # Reorder columns\n",
    "        ordered_columns = [name for name in scheme_display_names if name in show_verify_sum.columns]\n",
    "        show_verify_sum = show_verify_sum[ordered_columns]\n",
    "        \n",
    "        # Find minimum values\n",
    "        min_vals = show_verify_sum.min(axis=1)\n",
    "        \n",
    "        # Add summary header\n",
    "        table_rows.append(f\"\\\\multicolumn{{{len(ordered_columns)+1}}}{{c}}{{\\\\textbf{{Verify Phase Total (Show + Verify)}}}}  \\\\\\\\\")\n",
    "        table_rows.append(\"\\\\midrule\")\n",
    "        \n",
    "        # Add data rows\n",
    "        for idx in show_verify_sum.index:\n",
    "            row = [f\"\\\\textbf{{{idx}}}\"]\n",
    "            \n",
    "            for col in ordered_columns:\n",
    "                val = show_verify_sum.loc[idx, col]\n",
    "                # Bold if it's the minimum value\n",
    "                if val == min_vals[idx]:\n",
    "                    row.append(f\"\\\\textbf{{{val:.2f}}}\")\n",
    "                else:\n",
    "                    row.append(f\"{val:.2f}\")\n",
    "                    \n",
    "            table_rows.append(\" & \".join(row) + \" \\\\\\\\\")\n",
    "    \n",
    "    # Calculate number of columns for table specification\n",
    "    num_columns = len(scheme_display_names) + 1  # +1 for the 'n' column\n",
    "    \n",
    "    # Generate the complete LaTeX table\n",
    "    latex_code = f\"\"\"\\\\begin{{table}}[htbp]\n",
    "\\\\centering\n",
    "\\\\caption{{Performance of Anonymous Credential Operations (time in ms)}}\n",
    "\\\\label{{tab:anoncred_performance}}\n",
    "\\\\begin{{tabular}}{{@{{}}p{{1.2cm}}*{{{len(scheme_display_names)}}}{{>{{\\\\centering\\\\arraybackslash}}p{{1.6cm}}}}@{{}}}}\n",
    "\\\\toprule\n",
    "{column_headers} \\\\\\\\\n",
    "\\\\midrule\n",
    "{chr(10).join(table_rows)}\n",
    "\\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"LaTeX Table for Combined Operations with Summaries:\")\n",
    "    print(latex_code)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(\"combined_table_with_summaries.tex\", \"w\") as f:\n",
    "        f.write(latex_code)\n",
    "    \n",
    "    return latex_code\n",
    "combined_table = generate_combined_latex_table_with_summaries(benchmark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
