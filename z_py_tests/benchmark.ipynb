{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as snspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS Standard Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PS Protocol Benchmark Analysis\n",
      "Analyzing benchmark data from: ../target/criterion/ps_equality_split\n",
      "\n",
      "Found 5 proving and 5 verification configurations\n",
      "\n",
      "Analyzing proving configuration: 30\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_30/new/estimates.json\n",
      "✓ Successfully processed data for 30 credentials\n",
      "\n",
      "Analyzing proving configuration: 2\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_2/new/estimates.json\n",
      "✓ Successfully processed data for 2 credentials\n",
      "\n",
      "Analyzing proving configuration: 5\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_5/new/estimates.json\n",
      "✓ Successfully processed data for 5 credentials\n",
      "\n",
      "Analyzing proving configuration: 20\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_20/new/estimates.json\n",
      "✓ Successfully processed data for 20 credentials\n",
      "\n",
      "Analyzing proving configuration: 10\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_10/new/estimates.json\n",
      "✓ Successfully processed data for 10 credentials\n",
      "\n",
      "Scaling Analysis Summary:\n",
      "----------------------------------------------------------------------\n",
      " Credentials  Prove Time (ms)  Prove Std Dev  Verify Time (ms)  Verify Std Dev  Total Time (ms)\n",
      "           2        29.968961       0.370984         15.222588        0.039384        45.191549\n",
      "           5        70.733859       0.168195         38.078881        0.098659       108.812739\n",
      "          10       146.705128       1.713491         76.461643        0.467863       223.166771\n",
      "          20       285.085821       1.116339        154.356403        1.201041       439.442224\n",
      "          30       440.262785       8.795981        227.889103        0.360536       668.151888\n",
      "\n",
      "Scaling Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Credentials  | Prove Time           | Verify Time          | Prove Scaling   | Verify Scaling \n",
      "----------------------------------------------------------------------------------------------------\n",
      "5.0          |    70.73 ms |    38.08 ms |          0.94x |          1.00x\n",
      "10.0         |   146.71 ms |    76.46 ms |          1.04x |          1.00x\n",
      "20.0         |   285.09 ms |   154.36 ms |          0.97x |          1.01x\n",
      "30.0         |   440.26 ms |   227.89 ms |          1.03x |          0.98x\n",
      "\n",
      "Analysis complete! Check ps_credential_scaling_analysis.png for visualization\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_benchmark_data():\n",
    "    \"\"\"\n",
    "    Extract benchmark data for both proving and verification times from PS protocol benchmarks\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    base_path = Path(\"../target/criterion/ps_equality_split\")\n",
    "\n",
    "    print(f\"Analyzing benchmark data from: {base_path}\")\n",
    "\n",
    "    # Look for both prove and verify benchmarks\n",
    "    prove_dirs = list(base_path.glob(\"prove_credentials_*\"))\n",
    "    verify_dirs = list(base_path.glob(\"verify_credentials_*\"))\n",
    "\n",
    "    print(\n",
    "        f\"\\nFound {len(prove_dirs)} proving and {len(verify_dirs)} verification configurations\")\n",
    "\n",
    "    # Process proving benchmarks\n",
    "    for bench_dir in prove_dirs:\n",
    "        # Extract credential count from directory name\n",
    "        creds = int(bench_dir.name.split('_')[2])\n",
    "\n",
    "        estimates_file = bench_dir / \"new\" / \"estimates.json\"\n",
    "        print(f\"\\nAnalyzing proving configuration: {creds}\")\n",
    "        print(f\"Reading from: {estimates_file}\")\n",
    "\n",
    "        if estimates_file.exists():\n",
    "            try:\n",
    "                with open(estimates_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract timing metrics (converting nanoseconds to milliseconds)\n",
    "                mean_time = data['mean']['point_estimate'] / 1_000_000\n",
    "                std_dev = data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                # Find corresponding verification time\n",
    "                verify_dir = next(d for d in verify_dirs if int(\n",
    "                    d.name.split('_')[2]) == creds)\n",
    "                verify_estimates = verify_dir / \"new\" / \"estimates.json\"\n",
    "\n",
    "                with open(verify_estimates, 'r') as f:\n",
    "                    verify_data = json.load(f)\n",
    "\n",
    "                verify_mean = verify_data['mean']['point_estimate'] / 1_000_000\n",
    "                verify_std = verify_data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                results.append({\n",
    "                    'Credentials': creds,\n",
    "                    'Prove Time (ms)': mean_time,\n",
    "                    'Prove Std Dev': std_dev,\n",
    "                    'Verify Time (ms)': verify_mean,\n",
    "                    'Verify Std Dev': verify_std,\n",
    "                    'Total Time (ms)': mean_time + verify_mean\n",
    "                })\n",
    "                print(f\"✓ Successfully processed data for {creds} credentials\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"× Error processing data: {e}\")\n",
    "\n",
    "    if results:\n",
    "        # Create DataFrame and sort by credential count\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('Credentials')\n",
    "\n",
    "        # Save results\n",
    "        df.to_csv('ps_credential_scaling.csv', index=False)\n",
    "        df.to_json('ps_credential_scaling.json', orient='records', indent=2)\n",
    "\n",
    "        print(\"\\nScaling Analysis Summary:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"\\nNo data was collected!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_scaling(df):\n",
    "    \"\"\"Analyze and visualize scaling behavior for PS protocol proving and verification\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot proving time with error bars\n",
    "    plt.scatter(df['Credentials'], df['Prove Time (ms)'],\n",
    "                color='blue', label='Proving Time', s=100)\n",
    "    plt.errorbar(df['Credentials'], df['Prove Time (ms)'],\n",
    "                 yerr=df['Prove Std Dev'], fmt='none',\n",
    "                 capsize=5, color='blue', alpha=0.5)\n",
    "\n",
    "    # Plot verification time with error bars\n",
    "    plt.scatter(df['Credentials'], df['Verify Time (ms)'],\n",
    "                color='red', label='Verification Time', s=100)\n",
    "    plt.errorbar(df['Credentials'], df['Verify Time (ms)'],\n",
    "                 yerr=df['Verify Std Dev'], fmt='none',\n",
    "                 capsize=5, color='red', alpha=0.5)\n",
    "\n",
    "    # Plot total time\n",
    "    plt.scatter(df['Credentials'], df['Total Time (ms)'],\n",
    "                color='green', label='Total Time', s=100)\n",
    "\n",
    "    # Compute and plot ideal linear scaling for both operations\n",
    "    base_creds = df['Credentials'].iloc[0]\n",
    "    x_line = np.linspace(0, df['Credentials'].max() * 1.1, 100)\n",
    "\n",
    "    # Proving linear scaling\n",
    "    base_prove = df['Prove Time (ms)'].iloc[0]\n",
    "    y_prove = (base_prove/base_creds) * x_line\n",
    "    plt.plot(x_line, y_prove, '--', color='blue',\n",
    "             label='Ideal Linear (Prove)', alpha=0.5)\n",
    "\n",
    "    # Verification linear scaling\n",
    "    base_verify = df['Verify Time (ms)'].iloc[0]\n",
    "    y_verify = (base_verify/base_creds) * x_line\n",
    "    plt.plot(x_line, y_verify, '--', color='red',\n",
    "             label='Ideal Linear (Verify)', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Number of Credentials')\n",
    "    plt.ylabel('Execution Time (ms)')\n",
    "    plt.title('PS Protocol Credential Scaling Analysis')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the visualization\n",
    "    plt.savefig('ps_credential_scaling_analysis.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Print detailed scaling analysis\n",
    "    print(\"\\nScaling Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Credentials':<12} | {'Prove Time':<20} | {'Verify Time':<20} | {'Prove Scaling':<15} | {'Verify Scaling':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        prev = df.iloc[i-1]\n",
    "        curr = df.iloc[i]\n",
    "\n",
    "        cred_ratio = curr['Credentials'] / prev['Credentials']\n",
    "        prove_ratio = curr['Prove Time (ms)'] / prev['Prove Time (ms)']\n",
    "        verify_ratio = curr['Verify Time (ms)'] / prev['Verify Time (ms)']\n",
    "\n",
    "        prove_scaling = prove_ratio / cred_ratio\n",
    "        verify_scaling = verify_ratio / cred_ratio\n",
    "\n",
    "        print(f\"{curr['Credentials']:<12} | {curr['Prove Time (ms)']:>8.2f} ms | {curr['Verify Time (ms)']:>8.2f} ms | {prove_scaling:>13.2f}x | {verify_scaling:>13.2f}x\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Starting PS Protocol Benchmark Analysis\")\n",
    "    df = extract_benchmark_data()\n",
    "    if df is not None:\n",
    "        analyze_scaling(df)\n",
    "        print(\"\\nAnalysis complete! Check ps_credential_scaling_analysis.png for visualization\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSUTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing benchmark data from: ../target/criterion/psutt_split\n",
      "\n",
      "Found 5 proving and 5 verification configurations\n",
      "\n",
      "Analyzing proving configuration: 30\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_30/new/estimates.json\n",
      "✓ Successfully processed data for 30 credentials\n",
      "\n",
      "Analyzing proving configuration: 2\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_2/new/estimates.json\n",
      "✓ Successfully processed data for 2 credentials\n",
      "\n",
      "Analyzing proving configuration: 5\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_5/new/estimates.json\n",
      "✓ Successfully processed data for 5 credentials\n",
      "\n",
      "Analyzing proving configuration: 20\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_20/new/estimates.json\n",
      "✓ Successfully processed data for 20 credentials\n",
      "\n",
      "Analyzing proving configuration: 10\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_10/new/estimates.json\n",
      "✓ Successfully processed data for 10 credentials\n",
      "\n",
      "Scaling Analysis Summary:\n",
      "----------------------------------------------------------------------\n",
      " Credentials  Prove Time (ms)  Prove Std Dev  Verify Time (ms)  Verify Std Dev  Total Time (ms)\n",
      "           2         2.559354       0.014616          6.079918        0.019243         8.639272\n",
      "           5         6.471740       0.070918         15.193052        0.053837        21.664792\n",
      "          10        12.571747       0.119975         30.266927        0.050291        42.838674\n",
      "          20        24.951268       0.083301         60.018092        0.080534        84.969360\n",
      "          30        38.030850       0.440732         90.323018        0.437637       128.353868\n",
      "\n",
      "Scaling Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Credentials  | Prove Time           | Verify Time          | Prove Scaling   | Verify Scaling \n",
      "----------------------------------------------------------------------------------------------------\n",
      "5.0          |     6.47 ms |    15.19 ms |          1.01x |          1.00x\n",
      "10.0         |    12.57 ms |    30.27 ms |          0.97x |          1.00x\n",
      "20.0         |    24.95 ms |    60.02 ms |          0.99x |          0.99x\n",
      "30.0         |    38.03 ms |    90.32 ms |          1.02x |          1.00x\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_benchmark_data():\n",
    "    \"\"\"\n",
    "    Extract benchmark data for both proving and verification times\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    base_path = Path(\"../target/criterion/psutt_split\")\n",
    "\n",
    "    print(f\"Analyzing benchmark data from: {base_path}\")\n",
    "\n",
    "    # Look for both prove and verify benchmarks\n",
    "    prove_dirs = list(base_path.glob(\"prove_credentials_*\"))\n",
    "    verify_dirs = list(base_path.glob(\"verify_credentials_*\"))\n",
    "\n",
    "    print(\n",
    "        f\"\\nFound {len(prove_dirs)} proving and {len(verify_dirs)} verification configurations\")\n",
    "\n",
    "    # Process proving benchmarks\n",
    "    for bench_dir in prove_dirs:\n",
    "        # Extract credential count from directory name\n",
    "        creds = int(bench_dir.name.split('_')[2])\n",
    "\n",
    "        estimates_file = bench_dir / \"new\" / \"estimates.json\"\n",
    "        print(f\"\\nAnalyzing proving configuration: {creds}\")\n",
    "        print(f\"Reading from: {estimates_file}\")\n",
    "\n",
    "        if estimates_file.exists():\n",
    "            try:\n",
    "                with open(estimates_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract timing metrics (converting nanoseconds to milliseconds)\n",
    "                mean_time = data['mean']['point_estimate'] / 1_000_000\n",
    "                std_dev = data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                # Find corresponding verification time\n",
    "                verify_dir = next(d for d in verify_dirs if int(\n",
    "                    d.name.split('_')[2]) == creds)\n",
    "                verify_estimates = verify_dir / \"new\" / \"estimates.json\"\n",
    "\n",
    "                with open(verify_estimates, 'r') as f:\n",
    "                    verify_data = json.load(f)\n",
    "\n",
    "                verify_mean = verify_data['mean']['point_estimate'] / 1_000_000\n",
    "                verify_std = verify_data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                results.append({\n",
    "                    'Credentials': creds,\n",
    "                    'Prove Time (ms)': mean_time,\n",
    "                    'Prove Std Dev': std_dev,\n",
    "                    'Verify Time (ms)': verify_mean,\n",
    "                    'Verify Std Dev': verify_std,\n",
    "                    'Total Time (ms)': mean_time + verify_mean\n",
    "                })\n",
    "                print(f\"✓ Successfully processed data for {creds} credentials\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"× Error processing data: {e}\")\n",
    "\n",
    "    if results:\n",
    "        # Create DataFrame and sort by credential count\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('Credentials')\n",
    "\n",
    "        # Save results\n",
    "        df.to_csv('psutt_prover_verifier.csv', index=False)\n",
    "        df.to_json('psutt_prover_verifier.json', orient='records', indent=2)\n",
    "\n",
    "        print(\"\\nScaling Analysis Summary:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"\\nNo data was collected!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_scaling(df):\n",
    "    \"\"\"Analyze and visualize scaling behavior for both proving and verification\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot proving time\n",
    "    plt.scatter(df['Credentials'], df['Prove Time (ms)'],\n",
    "                color='blue', label='Proving Time', s=100)\n",
    "    if 'Prove Std Dev' in df.columns:\n",
    "        plt.errorbar(df['Credentials'], df['Prove Time (ms)'],\n",
    "                     yerr=df['Prove Std Dev'], fmt='none',\n",
    "                     capsize=5, color='blue', alpha=0.5)\n",
    "\n",
    "    # Plot verification time\n",
    "    plt.scatter(df['Credentials'], df['Verify Time (ms)'],\n",
    "                color='red', label='Verification Time', s=100)\n",
    "    if 'Verify Std Dev' in df.columns:\n",
    "        plt.errorbar(df['Credentials'], df['Verify Time (ms)'],\n",
    "                     yerr=df['Verify Std Dev'], fmt='none',\n",
    "                     capsize=5, color='red', alpha=0.5)\n",
    "\n",
    "    # Plot total time\n",
    "    plt.scatter(df['Credentials'], df['Total Time (ms)'],\n",
    "                color='green', label='Total Time', s=100)\n",
    "\n",
    "    # Compute and plot ideal linear scaling for both operations\n",
    "    base_creds = df['Credentials'].iloc[0]\n",
    "    x_line = np.linspace(0, df['Credentials'].max() * 1.1, 100)\n",
    "\n",
    "    # Proving linear scaling\n",
    "    base_prove = df['Prove Time (ms)'].iloc[0]\n",
    "    y_prove = (base_prove/base_creds) * x_line\n",
    "    plt.plot(x_line, y_prove, '--', color='blue',\n",
    "             label='Ideal Linear (Prove)', alpha=0.5)\n",
    "\n",
    "    # Verification linear scaling\n",
    "    base_verify = df['Verify Time (ms)'].iloc[0]\n",
    "    y_verify = (base_verify/base_creds) * x_line\n",
    "    plt.plot(x_line, y_verify, '--', color='red',\n",
    "             label='Ideal Linear (Verify)', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Number of Credentials')\n",
    "    plt.ylabel('Execution Time (ms)')\n",
    "    plt.title('PSUtt Credential Scaling Analysis: Proving vs Verification')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the visualization\n",
    "    plt.savefig('psutt_prover_verifier.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Print scaling analysis\n",
    "    print(\"\\nScaling Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Credentials':<12} | {'Prove Time':<20} | {'Verify Time':<20} | {'Prove Scaling':<15} | {'Verify Scaling':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        prev = df.iloc[i-1]\n",
    "        curr = df.iloc[i]\n",
    "\n",
    "        cred_ratio = curr['Credentials'] / prev['Credentials']\n",
    "        prove_ratio = curr['Prove Time (ms)'] / prev['Prove Time (ms)']\n",
    "        verify_ratio = curr['Verify Time (ms)'] / prev['Verify Time (ms)']\n",
    "\n",
    "        prove_scaling = prove_ratio / cred_ratio\n",
    "        verify_scaling = verify_ratio / cred_ratio\n",
    "\n",
    "        print(f\"{curr['Credentials']:<12} | {curr['Prove Time (ms)']:>8.2f} ms | {curr['Verify Time (ms)']:>8.2f} ms | {prove_scaling:>13.2f}x | {verify_scaling:>13.2f}x\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = extract_benchmark_data()\n",
    "    if df is not None:\n",
    "        analyze_scaling(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSUTT Improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing benchmark data from: ../target/criterion/psutt_improved_equality_split\n",
      "\n",
      "Found 5 proving and 5 verification configurations\n",
      "\n",
      "Analyzing proving configuration: 30\n",
      "Reading from: ../target/criterion/psutt_improved_equality_split/prove_credentials_30/new/estimates.json\n",
      "✓ Successfully processed data for 30 credentials\n",
      "\n",
      "Analyzing proving configuration: 2\n",
      "Reading from: ../target/criterion/psutt_improved_equality_split/prove_credentials_2/new/estimates.json\n",
      "✓ Successfully processed data for 2 credentials\n",
      "\n",
      "Analyzing proving configuration: 5\n",
      "Reading from: ../target/criterion/psutt_improved_equality_split/prove_credentials_5/new/estimates.json\n",
      "✓ Successfully processed data for 5 credentials\n",
      "\n",
      "Analyzing proving configuration: 20\n",
      "Reading from: ../target/criterion/psutt_improved_equality_split/prove_credentials_20/new/estimates.json\n",
      "✓ Successfully processed data for 20 credentials\n",
      "\n",
      "Analyzing proving configuration: 10\n",
      "Reading from: ../target/criterion/psutt_improved_equality_split/prove_credentials_10/new/estimates.json\n",
      "✓ Successfully processed data for 10 credentials\n",
      "\n",
      "PSUTT Improved Scaling Analysis Summary:\n",
      "----------------------------------------------------------------------\n",
      " Credentials  Prove Time (ms)  Prove Std Dev  Verify Time (ms)  Verify Std Dev  Total Time (ms)\n",
      "           2         4.059378       0.012951          4.860968        0.005413         8.920346\n",
      "           5         9.942890       0.033477         12.159577        0.042726        22.102467\n",
      "          10        19.728254       0.020736         24.320125        0.037448        44.048380\n",
      "          20        39.417406       0.082255         48.158411        0.106719        87.575817\n",
      "          30        59.299084       0.089086         72.016001        0.073402       131.315085\n",
      "\n",
      "Scaling Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Credentials  | Prove Time           | Verify Time          | Prove Scaling   | Verify Scaling \n",
      "----------------------------------------------------------------------------------------------------\n",
      "5.0          |     9.94 ms |    12.16 ms |          0.98x |          1.00x\n",
      "10.0         |    19.73 ms |    24.32 ms |          0.99x |          1.00x\n",
      "20.0         |    39.42 ms |    48.16 ms |          1.00x |          0.99x\n",
      "30.0         |    59.30 ms |    72.02 ms |          1.00x |          1.00x\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_benchmark_data():\n",
    "    \"\"\"\n",
    "    Extract benchmark data for both proving and verification times\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    base_path = Path(\"../target/criterion/psutt_improved_equality_split\")\n",
    "\n",
    "    print(f\"Analyzing benchmark data from: {base_path}\")\n",
    "\n",
    "    # Look for both prove and verify benchmarks\n",
    "    prove_dirs = list(base_path.glob(\"prove_credentials_*\"))\n",
    "    verify_dirs = list(base_path.glob(\"verify_credentials_*\"))\n",
    "\n",
    "    print(\n",
    "        f\"\\nFound {len(prove_dirs)} proving and {len(verify_dirs)} verification configurations\")\n",
    "\n",
    "    # Process proving benchmarks\n",
    "    for bench_dir in prove_dirs:\n",
    "        # Extract credential count from directory name\n",
    "        creds = int(bench_dir.name.split('_')[2])\n",
    "\n",
    "        estimates_file = bench_dir / \"new\" / \"estimates.json\"\n",
    "        print(f\"\\nAnalyzing proving configuration: {creds}\")\n",
    "        print(f\"Reading from: {estimates_file}\")\n",
    "\n",
    "        if estimates_file.exists():\n",
    "            try:\n",
    "                with open(estimates_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract timing metrics (converting nanoseconds to milliseconds)\n",
    "                mean_time = data['mean']['point_estimate'] / 1_000_000\n",
    "                std_dev = data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                # Find corresponding verification time\n",
    "                verify_dir = next(d for d in verify_dirs if int(\n",
    "                    d.name.split('_')[2]) == creds)\n",
    "                verify_estimates = verify_dir / \"new\" / \"estimates.json\"\n",
    "\n",
    "                with open(verify_estimates, 'r') as f:\n",
    "                    verify_data = json.load(f)\n",
    "\n",
    "                verify_mean = verify_data['mean']['point_estimate'] / 1_000_000\n",
    "                verify_std = verify_data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                results.append({\n",
    "                    'Credentials': creds,\n",
    "                    'Prove Time (ms)': mean_time,\n",
    "                    'Prove Std Dev': std_dev,\n",
    "                    'Verify Time (ms)': verify_mean,\n",
    "                    'Verify Std Dev': verify_std,\n",
    "                    'Total Time (ms)': mean_time + verify_mean\n",
    "                })\n",
    "                print(f\"✓ Successfully processed data for {creds} credentials\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"× Error processing data: {e}\")\n",
    "\n",
    "    if results:\n",
    "        # Create DataFrame and sort by credential count\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('Credentials')\n",
    "\n",
    "        # Save results\n",
    "        df.to_csv('psutt_improved_prover_verifier.csv', index=False)\n",
    "        df.to_json('psutt_improved_prover_verifier.json',\n",
    "                   orient='records', indent=2)\n",
    "\n",
    "        print(\"\\nPSUTT Improved Scaling Analysis Summary:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"\\nNo data was collected!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_scaling(df):\n",
    "    \"\"\"Analyze and visualize scaling behavior for both proving and verification\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot proving time\n",
    "    plt.scatter(df['Credentials'], df['Prove Time (ms)'],\n",
    "                color='blue', label='Proving Time', s=100)\n",
    "    if 'Prove Std Dev' in df.columns:\n",
    "        plt.errorbar(df['Credentials'], df['Prove Time (ms)'],\n",
    "                     yerr=df['Prove Std Dev'], fmt='none',\n",
    "                     capsize=5, color='blue', alpha=0.5)\n",
    "\n",
    "    # Plot verification time\n",
    "    plt.scatter(df['Credentials'], df['Verify Time (ms)'],\n",
    "                color='red', label='Verification Time', s=100)\n",
    "    if 'Verify Std Dev' in df.columns:\n",
    "        plt.errorbar(df['Credentials'], df['Verify Time (ms)'],\n",
    "                     yerr=df['Verify Std Dev'], fmt='none',\n",
    "                     capsize=5, color='red', alpha=0.5)\n",
    "\n",
    "    # Plot total time\n",
    "    plt.scatter(df['Credentials'], df['Total Time (ms)'],\n",
    "                color='green', label='Total Time', s=100)\n",
    "\n",
    "    # Compute and plot ideal linear scaling for both operations\n",
    "    base_creds = df['Credentials'].iloc[0]\n",
    "    x_line = np.linspace(0, df['Credentials'].max() * 1.1, 100)\n",
    "\n",
    "    # Proving linear scaling\n",
    "    base_prove = df['Prove Time (ms)'].iloc[0]\n",
    "    y_prove = (base_prove/base_creds) * x_line\n",
    "    plt.plot(x_line, y_prove, '--', color='blue',\n",
    "             label='Ideal Linear (Prove)', alpha=0.5)\n",
    "\n",
    "    # Verification linear scaling\n",
    "    base_verify = df['Verify Time (ms)'].iloc[0]\n",
    "    y_verify = (base_verify/base_creds) * x_line\n",
    "    plt.plot(x_line, y_verify, '--', color='red',\n",
    "             label='Ideal Linear (Verify)', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Number of Credentials')\n",
    "    plt.ylabel('Execution Time (ms)')\n",
    "    plt.title('PSUTT Improved Proving vs Verification')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the visualization\n",
    "    plt.savefig('psutt_improved_prover_verifier.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Print scaling analysis\n",
    "    print(\"\\nScaling Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Credentials':<12} | {'Prove Time':<20} | {'Verify Time':<20} | {'Prove Scaling':<15} | {'Verify Scaling':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        prev = df.iloc[i-1]\n",
    "        curr = df.iloc[i]\n",
    "\n",
    "        cred_ratio = curr['Credentials'] / prev['Credentials']\n",
    "        prove_ratio = curr['Prove Time (ms)'] / prev['Prove Time (ms)']\n",
    "        verify_ratio = curr['Verify Time (ms)'] / prev['Verify Time (ms)']\n",
    "\n",
    "        prove_scaling = prove_ratio / cred_ratio\n",
    "        verify_scaling = verify_ratio / cred_ratio\n",
    "\n",
    "        print(f\"{curr['Credentials']:<12} | {curr['Prove Time (ms)']:>8.2f} ms | {curr['Verify Time (ms)']:>8.2f} ms | {prove_scaling:>13.2f}x | {verify_scaling:>13.2f}x\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = extract_benchmark_data()\n",
    "    if df is not None:\n",
    "        analyze_scaling(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison PSUTT and PSUTT Improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Improvement Analysis:\n",
      "================================================================================\n",
      " Credentials  Prove Improvement (%)  Verify Improvement (%)  Total Improvement (%)\n",
      "           2                   0.11                    7.35                   4.19\n",
      "           5                   7.97                    2.16                   4.86\n",
      "          10                   3.81                    0.87                   2.21\n",
      "          20                   5.95                    2.25                   3.95\n",
      "          30                   3.04                    2.63                   2.81\n",
      "\n",
      "Scaling Analysis:\n",
      "================================================================================\n",
      "\n",
      "Credential increase 2 → 5:\n",
      "Original Prove scaling factor: 1.06x per credential ratio\n",
      "Improved Prove scaling factor: 0.98x per credential ratio\n",
      "Original Verify scaling factor: 0.95x per credential ratio\n",
      "Improved Verify scaling factor: 1.00x per credential ratio\n",
      "\n",
      "Credential increase 5 → 10:\n",
      "Original Prove scaling factor: 0.95x per credential ratio\n",
      "Improved Prove scaling factor: 0.99x per credential ratio\n",
      "Original Verify scaling factor: 0.99x per credential ratio\n",
      "Improved Verify scaling factor: 1.00x per credential ratio\n",
      "\n",
      "Credential increase 10 → 20:\n",
      "Original Prove scaling factor: 1.02x per credential ratio\n",
      "Improved Prove scaling factor: 1.00x per credential ratio\n",
      "Original Verify scaling factor: 1.00x per credential ratio\n",
      "Improved Verify scaling factor: 0.99x per credential ratio\n",
      "\n",
      "Credential increase 20 → 30:\n",
      "Original Prove scaling factor: 0.97x per credential ratio\n",
      "Improved Prove scaling factor: 1.00x per credential ratio\n",
      "Original Verify scaling factor: 1.00x per credential ratio\n",
      "Improved Verify scaling factor: 1.00x per credential ratio\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_data(original_file, improved_file):\n",
    "    \"\"\"Load both datasets for comparison\"\"\"\n",
    "    df_original = pd.read_csv(original_file)\n",
    "    df_improved = pd.read_csv(improved_file)\n",
    "    return df_original, df_improved\n",
    "\n",
    "def create_comparison_plot(df_original, df_improved):\n",
    "    \"\"\"Create a detailed comparison plot with error bars\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Set width of bars and positions of the bars\n",
    "    bar_width = 0.15\n",
    "    r1 = np.arange(len(df_original['Credentials']))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "    r4 = [x + bar_width for x in r3]\n",
    "    \n",
    "    # Create bars\n",
    "    plt.bar(r1, df_original['Prove Time (ms)'], bar_width, \n",
    "            label='Original Prove', color='blue', alpha=0.7,\n",
    "            yerr=df_original['Prove Std Dev'], capsize=5)\n",
    "    plt.bar(r2, df_improved['Prove Time (ms)'], bar_width,\n",
    "            label='Improved Prove', color='green', alpha=0.7,\n",
    "            yerr=df_improved['Prove Std Dev'], capsize=5)\n",
    "    plt.bar(r3, df_original['Verify Time (ms)'], bar_width,\n",
    "            label='Original Verify', color='red', alpha=0.7,\n",
    "            yerr=df_original['Verify Std Dev'], capsize=5)\n",
    "    plt.bar(r4, df_improved['Verify Time (ms)'], bar_width,\n",
    "            label='Improved Verify', color='orange', alpha=0.7,\n",
    "            yerr=df_improved['Verify Std Dev'], capsize=5)\n",
    "    \n",
    "    # Add labels and titles\n",
    "    plt.xlabel('Number of Credentials')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.title('Performance Comparison: Original vs Improved Implementation')\n",
    "    plt.xticks([r + bar_width*1.5 for r in range(len(df_original['Credentials']))],\n",
    "               df_original['Credentials'])\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ensure layout fits well\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('implementation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_improvements(df_original, df_improved):\n",
    "    \"\"\"Analyze and print improvement metrics\"\"\"\n",
    "    improvements = pd.DataFrame({\n",
    "        'Credentials': df_original['Credentials'],\n",
    "        'Prove Improvement (%)': ((df_original['Prove Time (ms)'] - df_improved['Prove Time (ms)']) \n",
    "                                 / df_original['Prove Time (ms)'] * 100),\n",
    "        'Verify Improvement (%)': ((df_original['Verify Time (ms)'] - df_improved['Verify Time (ms)'])\n",
    "                                  / df_original['Verify Time (ms)'] * 100),\n",
    "        'Total Improvement (%)': ((df_original['Total Time (ms)'] - df_improved['Total Time (ms)'])\n",
    "                                 / df_original['Total Time (ms)'] * 100)\n",
    "    })\n",
    "    \n",
    "    print(\"\\nPerformance Improvement Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(improvements.round(2).to_string(index=False))\n",
    "    \n",
    "    # Analyze scaling behavior\n",
    "    print(\"\\nScaling Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i in range(1, len(df_original)):\n",
    "        cred_ratio = df_original['Credentials'].iloc[i] / df_original['Credentials'].iloc[i-1]\n",
    "        \n",
    "        orig_prove_ratio = df_original['Prove Time (ms)'].iloc[i] / df_original['Prove Time (ms)'].iloc[i-1]\n",
    "        orig_verify_ratio = df_original['Verify Time (ms)'].iloc[i] / df_original['Verify Time (ms)'].iloc[i-1]\n",
    "        \n",
    "        imp_prove_ratio = df_improved['Prove Time (ms)'].iloc[i] / df_improved['Prove Time (ms)'].iloc[i-1]\n",
    "        imp_verify_ratio = df_improved['Verify Time (ms)'].iloc[i] / df_improved['Verify Time (ms)'].iloc[i-1]\n",
    "        \n",
    "        print(f\"\\nCredential increase {df_original['Credentials'].iloc[i-1]} → {df_original['Credentials'].iloc[i]}:\")\n",
    "        print(f\"Original Prove scaling factor: {orig_prove_ratio/cred_ratio:.2f}x per credential ratio\")\n",
    "        print(f\"Improved Prove scaling factor: {imp_prove_ratio/cred_ratio:.2f}x per credential ratio\")\n",
    "        print(f\"Original Verify scaling factor: {orig_verify_ratio/cred_ratio:.2f}x per credential ratio\")\n",
    "        print(f\"Improved Verify scaling factor: {imp_verify_ratio/cred_ratio:.2f}x per credential ratio\")\n",
    "\n",
    "def main():\n",
    "    # Load both datasets\n",
    "    df_original, df_improved = load_data('psutt_credential_scaling.csv', \n",
    "                                       'psutt_improved_prover_verifier.csv')\n",
    "    \n",
    "    # Create visualization\n",
    "    create_comparison_plot(df_original, df_improved)\n",
    "    \n",
    "    # Analyze improvements\n",
    "    analyze_improvements(df_original, df_improved)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
