{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as snspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS Standard Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PS Protocol Benchmark Analysis\n",
      "Analyzing benchmark data from: ../target/criterion/ps_equality_split\n",
      "\n",
      "Found 5 proving and 5 verification configurations\n",
      "\n",
      "Analyzing proving configuration: 30\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_30/new/estimates.json\n",
      "✓ Successfully processed data for 30 credentials\n",
      "\n",
      "Analyzing proving configuration: 2\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_2/new/estimates.json\n",
      "✓ Successfully processed data for 2 credentials\n",
      "\n",
      "Analyzing proving configuration: 5\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_5/new/estimates.json\n",
      "✓ Successfully processed data for 5 credentials\n",
      "\n",
      "Analyzing proving configuration: 20\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_20/new/estimates.json\n",
      "✓ Successfully processed data for 20 credentials\n",
      "\n",
      "Analyzing proving configuration: 10\n",
      "Reading from: ../target/criterion/ps_equality_split/prove_credentials_10/new/estimates.json\n",
      "✓ Successfully processed data for 10 credentials\n",
      "\n",
      "Scaling Analysis Summary:\n",
      "----------------------------------------------------------------------\n",
      " Credentials  Prove Time (ms)  Prove Std Dev  Verify Time (ms)  Verify Std Dev  Total Time (ms)\n",
      "           2        29.968961       0.370984         15.222588        0.039384        45.191549\n",
      "           5        70.733859       0.168195         38.078881        0.098659       108.812739\n",
      "          10       146.705128       1.713491         76.461643        0.467863       223.166771\n",
      "          20       285.085821       1.116339        154.356403        1.201041       439.442224\n",
      "          30       440.262785       8.795981        227.889103        0.360536       668.151888\n",
      "\n",
      "Scaling Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Credentials  | Prove Time           | Verify Time          | Prove Scaling   | Verify Scaling \n",
      "----------------------------------------------------------------------------------------------------\n",
      "5.0          |    70.73 ms |    38.08 ms |          0.94x |          1.00x\n",
      "10.0         |   146.71 ms |    76.46 ms |          1.04x |          1.00x\n",
      "20.0         |   285.09 ms |   154.36 ms |          0.97x |          1.01x\n",
      "30.0         |   440.26 ms |   227.89 ms |          1.03x |          0.98x\n",
      "\n",
      "Analysis complete! Check ps_credential_scaling_analysis.png for visualization\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_benchmark_data():\n",
    "    \"\"\"\n",
    "    Extract benchmark data for both proving and verification times from PS protocol benchmarks\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    base_path = Path(\"../target/criterion/ps_equality_split\")\n",
    "\n",
    "    print(f\"Analyzing benchmark data from: {base_path}\")\n",
    "\n",
    "    # Look for both prove and verify benchmarks\n",
    "    prove_dirs = list(base_path.glob(\"prove_credentials_*\"))\n",
    "    verify_dirs = list(base_path.glob(\"verify_credentials_*\"))\n",
    "\n",
    "    print(\n",
    "        f\"\\nFound {len(prove_dirs)} proving and {len(verify_dirs)} verification configurations\")\n",
    "\n",
    "    # Process proving benchmarks\n",
    "    for bench_dir in prove_dirs:\n",
    "        # Extract credential count from directory name\n",
    "        creds = int(bench_dir.name.split('_')[2])\n",
    "\n",
    "        estimates_file = bench_dir / \"new\" / \"estimates.json\"\n",
    "        print(f\"\\nAnalyzing proving configuration: {creds}\")\n",
    "        print(f\"Reading from: {estimates_file}\")\n",
    "\n",
    "        if estimates_file.exists():\n",
    "            try:\n",
    "                with open(estimates_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract timing metrics (converting nanoseconds to milliseconds)\n",
    "                mean_time = data['mean']['point_estimate'] / 1_000_000\n",
    "                std_dev = data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                # Find corresponding verification time\n",
    "                verify_dir = next(d for d in verify_dirs if int(\n",
    "                    d.name.split('_')[2]) == creds)\n",
    "                verify_estimates = verify_dir / \"new\" / \"estimates.json\"\n",
    "\n",
    "                with open(verify_estimates, 'r') as f:\n",
    "                    verify_data = json.load(f)\n",
    "\n",
    "                verify_mean = verify_data['mean']['point_estimate'] / 1_000_000\n",
    "                verify_std = verify_data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                results.append({\n",
    "                    'Credentials': creds,\n",
    "                    'Prove Time (ms)': mean_time,\n",
    "                    'Prove Std Dev': std_dev,\n",
    "                    'Verify Time (ms)': verify_mean,\n",
    "                    'Verify Std Dev': verify_std,\n",
    "                    'Total Time (ms)': mean_time + verify_mean\n",
    "                })\n",
    "                print(f\"✓ Successfully processed data for {creds} credentials\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"× Error processing data: {e}\")\n",
    "\n",
    "    if results:\n",
    "        # Create DataFrame and sort by credential count\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('Credentials')\n",
    "\n",
    "        # Save results\n",
    "        df.to_csv('ps_credential_scaling.csv', index=False)\n",
    "        df.to_json('ps_credential_scaling.json', orient='records', indent=2)\n",
    "\n",
    "        print(\"\\nScaling Analysis Summary:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"\\nNo data was collected!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_scaling(df):\n",
    "    \"\"\"Analyze and visualize scaling behavior for PS protocol proving and verification\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot proving time with error bars\n",
    "    plt.scatter(df['Credentials'], df['Prove Time (ms)'],\n",
    "                color='blue', label='Proving Time', s=100)\n",
    "    plt.errorbar(df['Credentials'], df['Prove Time (ms)'],\n",
    "                 yerr=df['Prove Std Dev'], fmt='none',\n",
    "                 capsize=5, color='blue', alpha=0.5)\n",
    "\n",
    "    # Plot verification time with error bars\n",
    "    plt.scatter(df['Credentials'], df['Verify Time (ms)'],\n",
    "                color='red', label='Verification Time', s=100)\n",
    "    plt.errorbar(df['Credentials'], df['Verify Time (ms)'],\n",
    "                 yerr=df['Verify Std Dev'], fmt='none',\n",
    "                 capsize=5, color='red', alpha=0.5)\n",
    "\n",
    "    # Plot total time\n",
    "    plt.scatter(df['Credentials'], df['Total Time (ms)'],\n",
    "                color='green', label='Total Time', s=100)\n",
    "\n",
    "    # Compute and plot ideal linear scaling for both operations\n",
    "    base_creds = df['Credentials'].iloc[0]\n",
    "    x_line = np.linspace(0, df['Credentials'].max() * 1.1, 100)\n",
    "\n",
    "    # Proving linear scaling\n",
    "    base_prove = df['Prove Time (ms)'].iloc[0]\n",
    "    y_prove = (base_prove/base_creds) * x_line\n",
    "    plt.plot(x_line, y_prove, '--', color='blue',\n",
    "             label='Ideal Linear (Prove)', alpha=0.5)\n",
    "\n",
    "    # Verification linear scaling\n",
    "    base_verify = df['Verify Time (ms)'].iloc[0]\n",
    "    y_verify = (base_verify/base_creds) * x_line\n",
    "    plt.plot(x_line, y_verify, '--', color='red',\n",
    "             label='Ideal Linear (Verify)', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Number of Credentials')\n",
    "    plt.ylabel('Execution Time (ms)')\n",
    "    plt.title('PS Protocol Credential Scaling Analysis')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the visualization\n",
    "    plt.savefig('ps_credential_scaling_analysis.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Print detailed scaling analysis\n",
    "    print(\"\\nScaling Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Credentials':<12} | {'Prove Time':<20} | {'Verify Time':<20} | {'Prove Scaling':<15} | {'Verify Scaling':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        prev = df.iloc[i-1]\n",
    "        curr = df.iloc[i]\n",
    "\n",
    "        cred_ratio = curr['Credentials'] / prev['Credentials']\n",
    "        prove_ratio = curr['Prove Time (ms)'] / prev['Prove Time (ms)']\n",
    "        verify_ratio = curr['Verify Time (ms)'] / prev['Verify Time (ms)']\n",
    "\n",
    "        prove_scaling = prove_ratio / cred_ratio\n",
    "        verify_scaling = verify_ratio / cred_ratio\n",
    "\n",
    "        print(f\"{curr['Credentials']:<12} | {curr['Prove Time (ms)']:>8.2f} ms | {curr['Verify Time (ms)']:>8.2f} ms | {prove_scaling:>13.2f}x | {verify_scaling:>13.2f}x\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Starting PS Protocol Benchmark Analysis\")\n",
    "    df = extract_benchmark_data()\n",
    "    if df is not None:\n",
    "        analyze_scaling(df)\n",
    "        print(\"\\nAnalysis complete! Check ps_credential_scaling_analysis.png for visualization\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSUTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing benchmark data from: ../target/criterion/psutt_split\n",
      "\n",
      "Found 5 proving and 5 verification configurations\n",
      "\n",
      "Analyzing proving configuration: 30\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_30/new/estimates.json\n",
      "✓ Successfully processed data for 30 credentials\n",
      "\n",
      "Analyzing proving configuration: 2\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_2/new/estimates.json\n",
      "✓ Successfully processed data for 2 credentials\n",
      "\n",
      "Analyzing proving configuration: 5\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_5/new/estimates.json\n",
      "✓ Successfully processed data for 5 credentials\n",
      "\n",
      "Analyzing proving configuration: 20\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_20/new/estimates.json\n",
      "✓ Successfully processed data for 20 credentials\n",
      "\n",
      "Analyzing proving configuration: 10\n",
      "Reading from: ../target/criterion/psutt_split/prove_credentials_10/new/estimates.json\n",
      "✓ Successfully processed data for 10 credentials\n",
      "\n",
      "Scaling Analysis Summary:\n",
      "----------------------------------------------------------------------\n",
      " Credentials  Prove Time (ms)  Prove Std Dev  Verify Time (ms)  Verify Std Dev  Total Time (ms)\n",
      "           2         2.559354       0.014616          6.079918        0.019243         8.639272\n",
      "           5         6.471740       0.070918         15.193052        0.053837        21.664792\n",
      "          10        12.571747       0.119975         30.266927        0.050291        42.838674\n",
      "          20        24.951268       0.083301         60.018092        0.080534        84.969360\n",
      "          30        38.030850       0.440732         90.323018        0.437637       128.353868\n",
      "\n",
      "Scaling Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Credentials  | Prove Time           | Verify Time          | Prove Scaling   | Verify Scaling \n",
      "----------------------------------------------------------------------------------------------------\n",
      "5.0          |     6.47 ms |    15.19 ms |          1.01x |          1.00x\n",
      "10.0         |    12.57 ms |    30.27 ms |          0.97x |          1.00x\n",
      "20.0         |    24.95 ms |    60.02 ms |          0.99x |          0.99x\n",
      "30.0         |    38.03 ms |    90.32 ms |          1.02x |          1.00x\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_benchmark_data():\n",
    "    \"\"\"\n",
    "    Extract benchmark data for both proving and verification times\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    base_path = Path(\"../target/criterion/psutt_split\")\n",
    "\n",
    "    print(f\"Analyzing benchmark data from: {base_path}\")\n",
    "\n",
    "    # Look for both prove and verify benchmarks\n",
    "    prove_dirs = list(base_path.glob(\"prove_credentials_*\"))\n",
    "    verify_dirs = list(base_path.glob(\"verify_credentials_*\"))\n",
    "\n",
    "    print(\n",
    "        f\"\\nFound {len(prove_dirs)} proving and {len(verify_dirs)} verification configurations\")\n",
    "\n",
    "    # Process proving benchmarks\n",
    "    for bench_dir in prove_dirs:\n",
    "        # Extract credential count from directory name\n",
    "        creds = int(bench_dir.name.split('_')[2])\n",
    "\n",
    "        estimates_file = bench_dir / \"new\" / \"estimates.json\"\n",
    "        print(f\"\\nAnalyzing proving configuration: {creds}\")\n",
    "        print(f\"Reading from: {estimates_file}\")\n",
    "\n",
    "        if estimates_file.exists():\n",
    "            try:\n",
    "                with open(estimates_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract timing metrics (converting nanoseconds to milliseconds)\n",
    "                mean_time = data['mean']['point_estimate'] / 1_000_000\n",
    "                std_dev = data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                # Find corresponding verification time\n",
    "                verify_dir = next(d for d in verify_dirs if int(\n",
    "                    d.name.split('_')[2]) == creds)\n",
    "                verify_estimates = verify_dir / \"new\" / \"estimates.json\"\n",
    "\n",
    "                with open(verify_estimates, 'r') as f:\n",
    "                    verify_data = json.load(f)\n",
    "\n",
    "                verify_mean = verify_data['mean']['point_estimate'] / 1_000_000\n",
    "                verify_std = verify_data['mean']['standard_error'] / 1_000_000\n",
    "\n",
    "                results.append({\n",
    "                    'Credentials': creds,\n",
    "                    'Prove Time (ms)': mean_time,\n",
    "                    'Prove Std Dev': std_dev,\n",
    "                    'Verify Time (ms)': verify_mean,\n",
    "                    'Verify Std Dev': verify_std,\n",
    "                    'Total Time (ms)': mean_time + verify_mean\n",
    "                })\n",
    "                print(f\"✓ Successfully processed data for {creds} credentials\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"× Error processing data: {e}\")\n",
    "\n",
    "    if results:\n",
    "        # Create DataFrame and sort by credential count\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('Credentials')\n",
    "\n",
    "        # Save results\n",
    "        df.to_csv('psutt_credential_scaling.csv', index=False)\n",
    "        df.to_json('psutt_credential_scaling.json', orient='records', indent=2)\n",
    "\n",
    "        print(\"\\nScaling Analysis Summary:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"\\nNo data was collected!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_scaling(df):\n",
    "    \"\"\"Analyze and visualize scaling behavior for both proving and verification\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot proving time\n",
    "    plt.scatter(df['Credentials'], df['Prove Time (ms)'],\n",
    "                color='blue', label='Proving Time', s=100)\n",
    "    if 'Prove Std Dev' in df.columns:\n",
    "        plt.errorbar(df['Credentials'], df['Prove Time (ms)'],\n",
    "                     yerr=df['Prove Std Dev'], fmt='none',\n",
    "                     capsize=5, color='blue', alpha=0.5)\n",
    "\n",
    "    # Plot verification time\n",
    "    plt.scatter(df['Credentials'], df['Verify Time (ms)'],\n",
    "                color='red', label='Verification Time', s=100)\n",
    "    if 'Verify Std Dev' in df.columns:\n",
    "        plt.errorbar(df['Credentials'], df['Verify Time (ms)'],\n",
    "                     yerr=df['Verify Std Dev'], fmt='none',\n",
    "                     capsize=5, color='red', alpha=0.5)\n",
    "\n",
    "    # Plot total time\n",
    "    plt.scatter(df['Credentials'], df['Total Time (ms)'],\n",
    "                color='green', label='Total Time', s=100)\n",
    "\n",
    "    # Compute and plot ideal linear scaling for both operations\n",
    "    base_creds = df['Credentials'].iloc[0]\n",
    "    x_line = np.linspace(0, df['Credentials'].max() * 1.1, 100)\n",
    "\n",
    "    # Proving linear scaling\n",
    "    base_prove = df['Prove Time (ms)'].iloc[0]\n",
    "    y_prove = (base_prove/base_creds) * x_line\n",
    "    plt.plot(x_line, y_prove, '--', color='blue',\n",
    "             label='Ideal Linear (Prove)', alpha=0.5)\n",
    "\n",
    "    # Verification linear scaling\n",
    "    base_verify = df['Verify Time (ms)'].iloc[0]\n",
    "    y_verify = (base_verify/base_creds) * x_line\n",
    "    plt.plot(x_line, y_verify, '--', color='red',\n",
    "             label='Ideal Linear (Verify)', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Number of Credentials')\n",
    "    plt.ylabel('Execution Time (ms)')\n",
    "    plt.title('PSUtt Credential Scaling Analysis: Proving vs Verification')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the visualization\n",
    "    plt.savefig('psutt_credential_scaling_analysis.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Print scaling analysis\n",
    "    print(\"\\nScaling Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Credentials':<12} | {'Prove Time':<20} | {'Verify Time':<20} | {'Prove Scaling':<15} | {'Verify Scaling':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        prev = df.iloc[i-1]\n",
    "        curr = df.iloc[i]\n",
    "\n",
    "        cred_ratio = curr['Credentials'] / prev['Credentials']\n",
    "        prove_ratio = curr['Prove Time (ms)'] / prev['Prove Time (ms)']\n",
    "        verify_ratio = curr['Verify Time (ms)'] / prev['Verify Time (ms)']\n",
    "\n",
    "        prove_scaling = prove_ratio / cred_ratio\n",
    "        verify_scaling = verify_ratio / cred_ratio\n",
    "\n",
    "        print(f\"{curr['Credentials']:<12} | {curr['Prove Time (ms)']:>8.2f} ms | {curr['Verify Time (ms)']:>8.2f} ms | {prove_scaling:>13.2f}x | {verify_scaling:>13.2f}x\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = extract_benchmark_data()\n",
    "    if df is not None:\n",
    "        analyze_scaling(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
